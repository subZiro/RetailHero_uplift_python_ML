{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт моделей\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, auc\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "from sklearn import metrics\n",
    "from sklearn.base import clone\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#графики\n",
    "import pylab as pl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uplift_fit_predict(model, X_train, treatment_train, target_train, X_test):\n",
    "    \"\"\"\n",
    "    Реализация простого способа построения uplift-модели.\n",
    "    \n",
    "    Обучаем два бинарных классификатора, которые оценивают вероятность target для клиента:\n",
    "    1. с которым была произведена коммуникация (treatment=1)\n",
    "    2. с которым не было коммуникации (treatment=0)\n",
    "    \n",
    "    В качестве оценки uplift для нового клиента берется разница оценок вероятностей:\n",
    "    Predicted Uplift = P(target|treatment=1) - P(target|treatment=0)\n",
    "    \"\"\"\n",
    "    X_treatment, y_treatment = X_train[treatment_train == 1, :], target_train[treatment_train == 1]\n",
    "    X_control, y_control = X_train[treatment_train == 0, :], target_train[treatment_train == 0]\n",
    "    model_treatment = clone(model).fit(X_treatment, y_treatment)\n",
    "    model_control = clone(model).fit(X_control, y_control)\n",
    "    predict_treatment = model_treatment.predict_proba(X_test)[:, 1]\n",
    "    predict_control = model_control.predict_proba(X_test)[:, 1]\n",
    "    predict_uplift = predict_treatment - predict_control\n",
    "    \n",
    "    return predict_uplift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uplift_score(prediction, treatment, target, rate=0.3):\n",
    "    \"\"\"Подсчет Uplift Score\"\"\"\n",
    "    order = numpy.argsort(-prediction)\n",
    "    treatment_n = int((treatment == 1).sum() * rate)\n",
    "    treatment_p = target[order][treatment[order] == 1][:treatment_n].mean()\n",
    "    control_n = int((treatment == 0).sum() * rate)\n",
    "    control_p = target[order][treatment[order] == 0][:control_n].mean()\n",
    "    score = treatment_p - control_p\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чтение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_products = pd.read_csv('../data_in/products.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_purchases = pd.read_csv('../data_in/purchases.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clients = pd.read_csv('../data_in/clients.csv', index_col='client_id')\n",
    "df_train = pd.read_csv('../data_in/uplift_train.csv', index_col='client_id')\n",
    "df_test = pd.read_csv('../data_in/uplift_test.csv', index_col='client_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Извлечение признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "извличение из таблицы клиенов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clients['first_issue_unixtime'] = pd.to_datetime(df_clients['first_issue_date']).astype(int)/10**9\n",
    "df_clients['first_redeem_unixtime'] = pd.to_datetime(df_clients['first_redeem_date']).astype(int)/10**9\n",
    "df_features = pd.DataFrame({\n",
    "    'gender_M': (df_clients['gender'] == 'M').astype(int),\n",
    "    'gender_F': (df_clients['gender'] == 'F').astype(int),\n",
    "    'gender_U': (df_clients['gender'] == 'U').astype(int),\n",
    "    'age': df_clients['age'],\n",
    "    'first_issue_time': df_clients['first_issue_unixtime'],\n",
    "    'first_redeem_time': df_clients['first_redeem_unixtime'],\n",
    "    'issue_redeem_delay': df_clients['first_redeem_unixtime'] - df_clients['first_issue_unixtime'],\n",
    "}).fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pandas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-154498af6d57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'age'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'age'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m101\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m90\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'age_group_kk'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'age'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m90\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m101\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pandas' is not defined"
     ]
    }
   ],
   "source": [
    "df_features['age'] = df_features['age'].apply(lambda x: 101 if x<0 or x>90 else x)\n",
    "df_features['age_group_kk'] = pandas.cut(df_features['age'], [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 101]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age_group = pandas.get_dummies(df_features['age_group_kk'],\n",
    "                                 prefix=\"age_group_kk\",\n",
    "                                 drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "извличение из таблицы заказы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#количество всех покупок, максимальная сумма покупки, минимальная, средняя, \n",
    "df_ps = df_purchases.groupby('client_id')['purchase_sum'].agg(\n",
    "    [('purchase_all_sum', lambda a: sum(list(a.unique()))), \n",
    "     ('purchase_all_min', 'min'),\n",
    "     ('purchase_all_max', 'max'),\n",
    "     ('purchase_all_mean', lambda a: a.unique().mean()),\n",
    "     ('purchase_all_std', lambda a: a.unique().std()),\n",
    "     ('transaction_count', lambda x: x.nunique())])\n",
    "\n",
    "\n",
    "#df_purchase_a = df_purchas.groupby('client_id')['purchase_sum'].agg(lambda x: x.nunique())\n",
    "\n",
    "#df_purchase_a = df_purchas.groupby('client_id')['purchase_sum'].agg(\n",
    "#    {'purchase_counts': lambda x: x.nunique()})\n",
    "\n",
    "#df_purchas.set_index('client_id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regular_points_received"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rpr = df_purchases.groupby('client_id')['regular_points_received'].agg(\n",
    "    [('rpr_median', lambda a: a.median()), \n",
    "     ('rpr_min', 'min'),\n",
    "     ('rpr_max', 'max'),\n",
    "     ('rpr_mean', lambda a: a.unique().mean()),\n",
    "     ('rpr_std', lambda a: a.unique().std())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "количество магазинов которые посетил клиент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_store = df_purchases.groupby('client_id')['store_id'].agg([('store_count', lambda a: len(set(a)))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Объединение признаков покупок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normaliz = pd.concat([df_ps, df_rpr, df_store], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нормализация количественных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Нормализация количественных признаков\n",
    "normlz = ['purchase_all_sum', 'purchase_all_min', 'purchase_all_max', \n",
    "          'purchase_all_mean', 'purchase_all_std', 'transaction_count',\n",
    "          'rpr_median', 'rpr_min', 'rpr_max', 'rpr_mean', 'rpr_std',\n",
    "          'store_count']\n",
    "\n",
    "df_normaliz = df_features[normlz]\n",
    "df_normaliz = (df_normaliz - df_normaliz.mean()) / df_normaliz.std()\n",
    "df_normaliz.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Объединение всех фич"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.concat([df_features, df_normaliz, df_age_group], axis=1)\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Очистка названий колонок от не читаемых символов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "df_features.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in df_features.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Удаление не нужных колонок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.drop(['age_group_kk'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оценка качества моделей на валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itog_val = {}\n",
    "kfold = 5\n",
    "random_state = 757"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_train = df_train.index\n",
    "indices_test = df_test.index\n",
    "indices_learn, indices_valid = train_test_split(df_train.index, test_size=0.3, random_state=random_state)\n",
    "\n",
    "X = df_features.loc[indices_learn, :].values\n",
    "y = df_train.loc[indices_learn, 'target'].values\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модель RandomForestClassifier\n",
    "model_rfc = RandomForestClassifier(random_state=random_state,\n",
    "                                   max_depth=9, \n",
    "                                   min_samples_leaf=1,\n",
    "                                   min_samples_split=4,\n",
    "                                   n_estimators=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модель GradientBoostingClassifier\n",
    "model_gbt = GradientBoostingClassifier(learning_rate=0.1,\n",
    "                                       min_samples_leaf=6,\n",
    "                                       min_samples_split=2,\n",
    "                                       n_estimators=200,\n",
    "                                       random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модель XGBClassifier\n",
    "model_xgbc = xgb.XGBClassifier(max_depth=10, \n",
    "                               min_child_weight=1,\n",
    "                               n_estimators=400, \n",
    "                               n_jobs=-1,\n",
    "                               verbose=1, \n",
    "                               learning_rate=0.15,\n",
    "                               seed=42, \n",
    "                               random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# модель LightGBM\n",
    "model_lgb = lgb.LGBMClassifier(silent=False,\n",
    "                              max_depth=4,\n",
    "                              learning_rate=0.01,\n",
    "                              num_leaves=60,\n",
    "                              n_estimators=300,\n",
    "                              random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model_rfc, X, y, cv=kfold)\n",
    "itog_val['RandomForestClassifier'] = scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model_gbt, X, y, cv=kfold)\n",
    "itog_val['GradientBoostingClassifier'] = scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model_xgbc, X, y, cv=kfold)\n",
    "itog_val['XGBClassifier'] = scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model_lgb, X, y, cv=kfold)\n",
    "itog_val['LightGBM'] = scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.from_dict(data=itog_val, orient='index').plot(kind='bar', legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Валидация моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_train = df_train.index\n",
    "indices_test = df_test.index\n",
    "indices_learn, indices_valid = train_test_split(df_train.index, test_size=0.33, random_state=random_state)\n",
    "\n",
    "\n",
    "valid_uplift = uplift_fit_predict(model=GradientBoostingClassifier(),\n",
    "                                  X_train=df_features.loc[indices_learn, :].fillna(0).values,\n",
    "                                  treatment_train=df_train.loc[indices_learn, 'treatment_flg'].values,\n",
    "                                  target_train=df_train.loc[indices_learn, 'target'].values,\n",
    "                                  X_test=df_features.loc[indices_valid, :].fillna(0).values,)\n",
    "\n",
    "valid_score = uplift_score(valid_uplift,\n",
    "                           treatment=df_train.loc[indices_valid, 'treatment_flg'].values,\n",
    "                           target=df_train.loc[indices_valid, 'target'].values,)\n",
    "print('Результат вализации:', valid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Validation score: GradientBoostingClassifier - 0.07547646591869583\n",
    "Validation score: model_gbc - 0.07364784854486317\n",
    "\n",
    "Validation score: xgb.XGBClassifier - \n",
    "Validation score: model_xgbc - \n",
    "\n",
    "Validation score: RandomForestClassifier - \n",
    "Validation score: model_rfc - \n",
    "\n",
    "Validation score: lgb.LGBMClassifier - \n",
    "Validation score: model_lgb - \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка предсказаний для тестовых клиентов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_uplift = uplift_fit_predict(\n",
    "    model=GradientBoostingClassifier(),\n",
    "    X_train=df_features.loc[indices_train, :].fillna(0).values,\n",
    "    treatment_train=df_train.loc[indices_train, 'treatment_flg'].values,\n",
    "    target_train=df_train.loc[indices_train, 'target'].values,\n",
    "    X_test=df_features.loc[indices_test, :].fillna(0).values,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сохранение предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_current = datetime.today().strftime('%d_%m_%H')\n",
    "df_submission = pandas.DataFrame({'uplift': test_uplift}, index=df_test.index)\n",
    "df_submission.to_csv(f'../data_out/submission_{date_current}.csv')\n",
    "print('file saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best public csore: 0,0782"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
