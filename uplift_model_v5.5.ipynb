{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт моделей\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import clone\n",
    "\n",
    "#графики\n",
    "import pylab as pl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_duplicate_col(df):\n",
    "    '''удаление повторяющихся строк по столбцу client_id'''\n",
    "    print(f'до: {df.shape[0]}')\n",
    "    df.reset_index(inplace=True, drop=False)\n",
    "    duplicate_index = df[df['client_id'].duplicated()].index\n",
    "    duplicate_index.append(duplicate_index-1)\n",
    "    df = df.drop(duplicate_index)\n",
    "    df.set_index('client_id', inplace=True)\n",
    "    print(f'после: {df.shape[0]}')\n",
    "    return df\n",
    "\n",
    "\n",
    "def f_create_agegroup(df_features):\n",
    "    '''создание фич возрастных категорий'''\n",
    "    df_features['age'] = df_features['age'].apply(lambda x: 99 if x<0 or x>90 else x)\n",
    "    df_features['age_group_kk'] = pd.cut(df_features['age'], [0,10,20,30,40,50,60,70,80,90]) \n",
    "    df_age_group = pd.get_dummies(df_features['age_group_kk'],\n",
    "                                  prefix=\"age_group_kk\",\n",
    "                                  drop_first=True)\n",
    "    print('Создание категорий возрастов завершено')\n",
    "    return df_age_group\n",
    "\n",
    "\n",
    "def clear_bad_col(df):\n",
    "    '''Очистка названий колонок от не читаемых символов'''\n",
    "    regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "    df.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col \n",
    "                  for col in df.columns.values]\n",
    "    return df\n",
    "\n",
    "\n",
    "def f_normaliz_df(df, col):\n",
    "    '''нормализация количественных данных'''\n",
    "    df[col] = (df[col] - df[col].mean()) / df[col].std()\n",
    "    print('Данные нормализованы')\n",
    "    return df\n",
    "\n",
    "\n",
    "def f_is_alhocol(df):\n",
    "    #приобретался ли алкоголь\n",
    "    df['is_alhocol'] = df['alhocol'].apply(lambda x: 0 if x==0 else 1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def f_group_future(df):\n",
    "    df['sum_quantity'] = df['sum'] / df['quantity']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_processing_purchase_sum_col(df_purchases):\n",
    "    '''извличение из таблицы заказы\n",
    "    количество всех покупок, максимальная сумма покупки, минимальная, средняя''' \n",
    "    df_ps = df_purchases.groupby('client_id')['purchase_sum'].agg(\n",
    "        [('purchase_all_sum', lambda a: sum(list(a.unique()))), \n",
    "         ('purchase_all_min', 'min'),\n",
    "         ('purchase_all_max', 'max'),\n",
    "         ('purchase_all_mean', lambda a: a.unique().mean()),\n",
    "         ('purchase_all_std', lambda a: a.unique().std())])\n",
    "    print('Извличение признаков из purchase_sum завершено')\n",
    "    return df_ps\n",
    "\n",
    "\n",
    "def f_processing_rpr_column(df_purchases):\n",
    "    '''regular_points_received + store'''\n",
    "    df_rpr = df_purchases.groupby('client_id')['regular_points_received'].agg(\n",
    "        [('rpr_median', lambda a: a.median()), \n",
    "         ('rpr_min', 'min'),\n",
    "         ('rpr_max', 'max'),\n",
    "         ('rpr_mean', lambda a: a.unique().mean()),\n",
    "         ('rpr_std', lambda a: a.unique().std())])\n",
    "    print('Обработка regular_points_received завершена')\n",
    "    return df_rpr\n",
    "\n",
    "\n",
    "def f_onestore(df_purchases):\n",
    "    '''Подсчет количества посещеных магазинов'''\n",
    "    df_store = df_purchases.groupby('client_id')['store_id'].agg([('store_count', lambda a: len(set(a)))])\n",
    "    df_store['is_one_store'] = df_store['store_count'].apply(lambda x: 1 if x == 1 else 0)\n",
    "    print('Обработка store завершена')\n",
    "    return df_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_broke_age(features_set):\n",
    "    '''Это функция тренирует модель на предсказание возраста и делает предсказание ошибочного возраста.\n",
    "    Под ошибочным понимается тот, который выбивается из интервала 14-95 лет'''\n",
    "\n",
    "    print('Запущена модель для корректировки неправильного возраста клиентов')\n",
    "    broke_age_index = features_set[(features_set['age']<14) | (features_set['age']>95)].index\n",
    "\n",
    "    X = features_set[~features_set.index.isin(broke_age_index)].drop(['age', 'client_id'], axis=1)\n",
    "    y = features_set[~features_set.index.isin(broke_age_index)]['age']\n",
    "    params = {'n_jobs': -1,\n",
    "              'seed': 42,\n",
    "              'boosting_type': 'gbdt',\n",
    "              'objective': 'regression',\n",
    "              'metric': 'rmse',\n",
    "              'verbose': -1}\n",
    "    \n",
    "    train_set = lgb.Dataset(X.iloc[:30000], y[:30000])\n",
    "    val_set = lgb.Dataset(X.iloc[-5000:], y[-5000:])\n",
    "    model = lgb.train(params=params,\n",
    "                      train_set = train_set,\n",
    "                      valid_sets = [train_set, val_set],\n",
    "                      num_boost_round=5000,\n",
    "                      early_stopping_rounds=100,\n",
    "                      verbose_eval=False)\n",
    "    \n",
    "    age_predict = model.predict(features_set.loc[broke_age_index, :].drop(['age', 'client_id'], axis=1),\\\n",
    "                                num_iteration = model.best_iteration)\n",
    "    \n",
    "    features_set.loc[broke_age_index, 'age'] = age_predict.astype(int)\n",
    "    print('Корректрировка возростов выполнена')\n",
    "    return features_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чтение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data_in/uplift_train.csv', index_col='client_id')\n",
    "df_test = pd.read_csv('../data_in/uplift_test.csv', index_col='client_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clients = pd.read_csv('../data_in/clients.csv', index_col='client_id')\n",
    "df_purchases = pd.read_csv('../data_in/purchases.csv', index_col='client_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_products = pd.read_csv('../data_in/products.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# чтение test, train с подготовлеными признаками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from Features_Generator import Features_Generator\n",
    "#Инициализируем класс, указывая путь к папке с файлами\n",
    "fg = Features_Generator('../data_in/')\n",
    "df_train_f, df_test_f = fg.create_features(low_memory=True, save_files=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_f = pd.read_csv('../data_in/features_set_train.csv', index_col='client_id')\n",
    "df_test_f = pd.read_csv('../data_in/features_set_test.csv', index_col='client_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_f.shape, df_test_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "до: 400206\n",
      "после: 400162\n"
     ]
    }
   ],
   "source": [
    "# объединение данных с тренировочными и тестовыми данными\n",
    "df_fix = pd.concat([df_train_f, df_test_f], ignore_index=False, sort=False)\n",
    "\n",
    "# удаление дублирующихся строк\n",
    "df_fix = del_duplicate_col(df_fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создание категорий возрастов завершено\n"
     ]
    }
   ],
   "source": [
    "# создание категорий возрастов\n",
    "df_age = f_create_agegroup(df_fix)\n",
    "\n",
    "# очистка названий колонок от не читаемых символов\n",
    "df_age = clear_bad_col(df_age)\n",
    "\n",
    "# объединение фреймов\n",
    "df_fix = pd.concat([df_fix, df_age], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаление не нужных столбцов\n",
    "df_fix.drop(['treatment_flg', 'target', 'age_group_kk'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные нормализованы\n"
     ]
    }
   ],
   "source": [
    "# нормализация количественных данных\n",
    "col = df_fix.columns\n",
    "df_fix = f_normaliz_df(df_fix, col[:179])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# приобретал ли алкоголь\n",
    "df_fix = f_is_alhocol(df_fix)\n",
    "\n",
    "df_fix = f_group_future(df_fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ps = f_processing_purchase_sum_col(df_purchases)\n",
    "df_rpr = f_processing_rpr_column(df_purchases)\n",
    "df_store = f_onestore(df_purchases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "'''\n",
    "df_ps.to_csv(f'../data_in/df_ps.csv')\n",
    "df_rpr.to_csv(f'../data_in/df_rpr.csv')\n",
    "df_store.to_csv(f'../data_in/df_store.csv')\n",
    "\n",
    "df_ps = pd.read_csv('../data_in/df_ps.csv', index_col='client_id')\n",
    "df_rpr = pd.read_csv('../data_in/df_rpr.csv', index_col='client_id')\n",
    "df_store = pd.read_csv('../data_in/df_store.csv', index_col='client_id')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# копирование подготовленного фрейма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.concat([df_fix, df_rpr, df_store], axis=1, sort=False)\n",
    "df_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оценка качества моделей на валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 777"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модель RandomForestClassifier\n",
    "model_rfc = RandomForestClassifier(random_state=random_state,\n",
    "                                   max_depth=9, \n",
    "                                   min_samples_leaf=1,\n",
    "                                   min_samples_split=4,\n",
    "                                   n_estimators=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'learning_rate=0.05,\\n   min_samples_leaf=6,\\n   min_samples_split=2,\\n   n_estimators=90,\\n   valid - 0.765\\n   \\n   learning_rate=0.05,\\n   min_samples_leaf=14,\\n   min_samples_split=2,\\n   n_estimators=100,\\n   valid - 0.793\\n'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Модель GradientBoostingClassifier\n",
    "model_gbc = GradientBoostingClassifier(learning_rate=0.05,\n",
    "                                       min_samples_leaf=14,\n",
    "                                       min_samples_split=2,\n",
    "                                       n_estimators=110,\n",
    "                                       random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модель XGBClassifier\n",
    "model_xgbc = xgb.XGBClassifier(max_depth=10, \n",
    "                               min_child_weight=1,\n",
    "                               n_estimators=400, \n",
    "                               n_jobs=-1,\n",
    "                               verbose=1, \n",
    "                               learning_rate=0.15,\n",
    "                               seed=42, \n",
    "                               random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# модель LightGBM\n",
    "model_lgb = lgb.LGBMClassifier(silent=False,\n",
    "                              max_depth=4,\n",
    "                              learning_rate=0.01,\n",
    "                              num_leaves=60,\n",
    "                              n_estimators=300,\n",
    "                              random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uplift модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uplift_fit_predict(model, X_train, treatment_train, target_train, X_test):\n",
    "    \"\"\"\n",
    "    Реализация простого способа построения uplift-модели.\n",
    "    \n",
    "    Обучаем два бинарных классификатора, которые оценивают вероятность target для клиента:\n",
    "    1. с которым была произведена коммуникация (treatment=1)\n",
    "    2. с которым не было коммуникации (treatment=0)\n",
    "    \n",
    "    В качестве оценки uplift для нового клиента берется разница оценок вероятностей:\n",
    "    Predicted Uplift = P(target|treatment=1) - P(target|treatment=0)\n",
    "    \"\"\"\n",
    "    X_treatment, y_treatment = X_train[treatment_train == 1, :], target_train[treatment_train == 1]\n",
    "    X_control, y_control = X_train[treatment_train == 0, :], target_train[treatment_train == 0]\n",
    "    model_treatment = clone(model).fit(X_treatment, y_treatment)\n",
    "    model_control = clone(model).fit(X_control, y_control)\n",
    "    predict_treatment = model_treatment.predict_proba(X_test)[:, 1]\n",
    "    predict_control = model_control.predict_proba(X_test)[:, 1]\n",
    "    predict_uplift = predict_treatment - predict_control\n",
    "    \n",
    "    return predict_uplift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uplift_score(prediction, treatment, target, rate=0.3):\n",
    "    \"\"\"\n",
    "    Подсчет Uplift Score\n",
    "    \"\"\"\n",
    "    order = np.argsort(-prediction)\n",
    "    treatment_n = int((treatment == 1).sum() * rate)\n",
    "    treatment_p = target[order][treatment[order] == 1][:treatment_n].mean()\n",
    "    control_n = int((treatment == 0).sum() * rate)\n",
    "    control_p = target[order][treatment[order] == 0][:control_n].mean()\n",
    "    score = treatment_p - control_p\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат вализации: 0.07713872525484533\n"
     ]
    }
   ],
   "source": [
    "indices_train = df_train.index\n",
    "indices_test = df_test.index\n",
    "indices_learn, indices_valid = train_test_split(df_train.index, test_size=0.33, random_state=random_state)\n",
    "\n",
    "valid_uplift = uplift_fit_predict(model=model_gbc,\n",
    "                                  X_train=df_features.loc[indices_learn, :].fillna(0).values,\n",
    "                                  treatment_train=df_train.loc[indices_learn, 'treatment_flg'].values,\n",
    "                                  target_train=df_train.loc[indices_learn, 'target'].values,\n",
    "                                  X_test=df_features.loc[indices_valid, :].fillna(0).values,)\n",
    "\n",
    "valid_score = uplift_score(valid_uplift,\n",
    "                           treatment=df_train.loc[indices_valid, 'treatment_flg'].values,\n",
    "                           target=df_train.loc[indices_valid, 'target'].values,)\n",
    "print('Результат вализации:', valid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Validation score: GradientBoostingClassifier - 0.08173617384321996\n",
    "Validation score: model_gbc - 0.0793815597055414 - 0.932\n",
    "Validation score: model_gbc - 0.08130959550336248 - 0.918\n",
    "\n",
    "Validation score: lgb.LGBMClassifier - 0.0632743393973555\n",
    "Validation score: model_lgb - 0.0632743393973555\n",
    "\n",
    "Validation score: RandomForestClassifier - 0.05228844390221066\n",
    "Validation score: model_rfc - 0.059314655643286085\n",
    "\n",
    "Validation score: xgb.XGBClassifier - 0.0820561075981131\n",
    "Validation score: model_xgbc - 0.06607721690851454\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка предсказаний для тестовых клиентов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_uplift = uplift_fit_predict(\n",
    "    model=model_gbc,\n",
    "    X_train=df_features.loc[indices_train, :].fillna(0).values,\n",
    "    treatment_train=df_train.loc[indices_train, 'treatment_flg'].values,\n",
    "    target_train=df_train.loc[indices_train, 'target'].values,\n",
    "    X_test=df_features.loc[indices_test, :].fillna(0).values,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сохранение предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved!\n"
     ]
    }
   ],
   "source": [
    "date_current = datetime.today().strftime('%d_%m_%H')\n",
    "df_submission = pd.DataFrame({'uplift': test_uplift}, index=df_test.index)\n",
    "df_submission.to_csv(f'../data_out/submission_v5.5_{date_current}.csv')\n",
    "print('file saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "Public score = 0.930\n",
    "##################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
